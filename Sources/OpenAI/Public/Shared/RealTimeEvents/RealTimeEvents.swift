//
//  RealTimeEvents.swift
//  SwiftOpenAI
//
//  Created by James Rochabrun on 1/4/25.
//

import Foundation

public protocol RealTimeEvent {
   var eventId: String { get }
   var type: String { get }
}

/// The conversation resource.
public struct ConversationResource: Decodable {
   
   /// The unique ID of the conversation.
   public let id: String
   /// The object type, must be realtime.conversation.
   public let object: String = "realtime.conversation"
}

/// The response resource.
public struct ResponseResource: Codable {
   
   /// The unique ID of the response.
   public let id: String
   /// The object type, must be realtime.response.
   public let object: String = "realtime.response"
   /// The final status of the response (completed, cancelled, failed, or incomplete).
   public let status: String
   /// Additional details about the status.
   public let statusDetails: StatusDetails?
   /// The list of output items generated by the response.
   public let output: [ConversationItem]
   /// Developer-provided string key-value pairs associated with this response.
   public let metadata: [String: String]?
   /// Usage statistics for the Response, this will correspond to billing. A Realtime API session will maintain a conversation context and append new Items to the Conversation, thus output from previous turns (text and audio tokens) will become the input for later turns.
   public let usage: ResponseUsage?
   
   enum CodingKeys: String, CodingKey {
      case id
      case object
      case status
      case statusDetails = "status_details"
      case output
      case metadata
      case usage
   }
}

/// Additional details about the status.
public struct StatusDetails: Codable {
   
   /// The type of error that caused the response to fail, corresponding with the status field (completed, cancelled, incomplete, failed).
   public let type: String
   /// The reason the Response did not complete. For a cancelled Response, one of turn_detected (the server VAD detected a new start of speech) or client_cancelled (the client sent a cancel event). For an incomplete Response, one of max_output_tokens or content_filter (the server-side safety filter activated and cut off the response).
   public let reason: String
   /// A description of the error that caused the response to fail, populated when the status is failed.
   public let error: ErrorDetails?
}

public struct ResponseUsage: Codable {
   
   /// The total number of tokens in the Response including input and output text and audio tokens.
   public let totalTokens: Int
   /// The number of input tokens used in the Response, including text and audio tokens.
   public let inputTokens: Int
   /// The number of output tokens sent in the Response, including text and audio tokens.
   public let outputTokens: Int
   /// Details about the input tokens used in the Response.
   public let inputTokenDetails: InputTokenDetails
   /// Details about the output tokens used in the Response.
   public let outputTokenDetails: OutputTokenDetails
   
   enum CodingKeys: String, CodingKey {
      case totalTokens = "total_tokens"
      case inputTokens = "input_tokens"
      case outputTokens = "output_tokens"
      case inputTokenDetails = "input_token_details"
      case outputTokenDetails = "output_token_details"
   }
}

public struct InputTokenDetails: Codable {
   
   /// The number of cached tokens used in the Response.
   public let cachedTokens: Int
   /// The number of text tokens used in the Response.
   public let textTokens: Int
   /// The number of audio tokens used in the Response.
   public let audioTokens: Int
   public let cachedTokensDetails: CachedTokensDetails?
   
   enum CodingKeys: String, CodingKey {
      case cachedTokens = "cached_tokens"
      case textTokens = "text_tokens"
      case audioTokens = "audio_tokens"
      case cachedTokensDetails = "cached_tokens_details"
   }
}

public struct CachedTokensDetails: Codable {
   public let textTokens: Int
   public let audioTokens: Int
   
   enum CodingKeys: String, CodingKey {
      case textTokens = "text_tokens"
      case audioTokens = "audio_tokens"
   }
}

public struct OutputTokenDetails: Codable {
   
   /// The number of text tokens used in the Response.
   public let textTokens: Int
   /// The number of audio tokens used in the Response.
   public let audioTokens: Int
   
   enum CodingKeys: String, CodingKey {
      case textTokens = "text_tokens"
      case audioTokens = "audio_tokens"
   }
}


// MARK: - Conversation Item

public struct ConversationItem: Codable {
   
   /// The unique ID of the item, this can be generated by the client to help manage server-side context, but is not required because the server will generate one if not provided.
   public let id: String?
   
   /// The type of the item (message, function_call, function_call_output).
   public let type: String
   
   /// Identifier for the API object being returned - always realtime.item.
   public let object: String
   
   /// The status of the item (completed, incomplete). These have no effect on the conversation, but are accepted for consistency with the conversation.item.created event.
   public let status: String
   
   /// The role of the message sender (user, assistant, system), only applicable for message items.
   public let role: String
   
   /// The content of the message, applicable for message items.
   public let content: [ContentPart]?
   
   /// The ID of the function call (for function_call and function_call_output items). If passed on a function_call_output item, the server will check that a function_call item with the same ID exists in the conversation history.
   public let callId: String?
   
   /// The name of the function being called (for function_call items).
   public let name: String?
   
   /// The arguments of the function call (for function_call items).
   public let arguments: String?
   
   /// The output of the function call (for function_call_output items).
   public let output: String?
   
   enum CodingKeys: String, CodingKey {
      case id
      case type
      case object
      case status
      case role
      case content
      case callId = "call_id"
      case name
      case arguments
      case output
   }
   
   public init(
      id: String?,
      type: ItemType,
      object: String,
      status: ItemStatus,
      role: Role,
      content: [ContentPart]?,
      callId: String?,
      name: String?,
      arguments: String?,
      output: String?)
   {
      self.id = id
      self.type = type.rawValue
      self.object = object
      self.status = status.rawValue
      self.role = role.rawValue
      self.content = content
      self.callId = callId
      self.name = name
      self.arguments = arguments
      self.output = output
   }
}

// MARK: - Item Types

/// The type of the item (message, function_call, function_call_output).
public enum ItemType: String, Codable {
   case message
   case functionCall = "function_call"
   case functionCallOutput = "function_call_output"
}

/// The content of the message, applicable for message items.
///
/// Message items of role system support only input_text content
/// Message items of role user support input_text and input_audio content
/// Message items of role assistant support text content.
public struct ContentPart: Codable {
   
   /// The content type (input_text, input_audio, item_reference, text).
   public let type: String
   /// The text content, used for input_text and text content types.
   public let text: String
   /// ID of a previous conversation item to reference (for item_reference content types in response.create events). These can reference both client and server created items.
   public let id: String
   /// Base64-encoded audio bytes, used for input_audio content type.
   public let audio: String?
   /// The transcript of the audio, used for input_audio content type.
   public let transcript: String?
   
   enum CodingKeys: String, CodingKey {
      case type
      case text
      case id
      case audio
      case transcript
   }
   
   public init(
      type: ContentType,
      text: String,
      id: String,
      audio: String?,
      transcript: String?)
   {
      self.type = type.rawValue
      self.text = text
      self.id = id
      self.audio = audio
      self.transcript = transcript
   }
}

public enum ContentType: String, Codable {
   
   case text
   case inputText = "input_text"
   case inputAudio = "input_audio"
   case item_reference = "item_reference"
}

/// The status of the item (completed, incomplete). These have no effect on the conversation, but are accepted for consistency with the conversation.item.created event.
public enum ItemStatus: String, Codable {
   case completed
   case incomplete
}

public enum Role: String, Codable {
   case system
   case user
   case assistant
}

// MARK: - Response Create Parameters

public struct RealTimeResponse: Encodable {
   
   /// The set of modalities the model can respond with. To disable audio, set this to ["text"].
   public let modalities: [String]?
   /// The default system instructions (i.e. system message) prepended to model calls. This field allows the client to guide the model on desired responses. The model can be instructed on response content and format, (e.g. "be extremely succinct", "act friendly", "here are examples of good responses") and on audio behavior (e.g. "talk quickly", "inject emotion into your voice", "laugh frequently"). The instructions are not guaranteed to be followed by the model, but they provide guidance to the model on the desired behavior.
   /// Note that the server sets default instructions which will be used if this field is not set and are visible in the session.created event at the start of the session.
   public let instructions: String?
   /// The voice the model uses to respond. Voice cannot be changed during the session once the model has responded with audio at least once. Current voice options are alloy, ash, ballad, coral, echo sage, shimmer and verse.
   public let voice: String?
   /// The format of output audio. Options are pcm16, g711_ulaw, or g711_alaw.
   public let outputAudioFormat: String?
   /// Tools (functions) available to the model.
   public let tools: [Tool]?
   /// How the model chooses tools. Options are auto, none, required, or specify a function, like {"type": "function", "function": {"name": "my_function"}}.
   public let toolChoice: ToolChoice?
   /// Sampling temperature for the model, limited to [0.6, 1.2]. Defaults to 0.8.
   public let temperature: Double?
   /// Maximum number of output tokens for a single assistant response, inclusive of tool calls. Provide an integer between 1 and 4096 to limit output tokens, or inf for the maximum available tokens for a given model. Defaults to inf.
   public let maxResponseOutputTokens: TokenLimit?
   /// Controls which conversation the response is added to. Currently supports auto and none, with auto as the default value. The auto value means that the contents of the response will be added to the default conversation. Set this to none to create an out-of-band response which will not add items to default conversation.
   public let conversation: ConversationType?
   /// Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maximum of 512 characters long.
   public let metadata: [String: String]?
   /// Input items to include in the prompt for the model. Creates a new context for this response, without including the default conversation. Can include references to items from the default conversation.
   public let input: [ConversationItem]?
   
   enum CodingKeys: String, CodingKey {
      case modalities
      case instructions
      case voice
      case outputAudioFormat = "output_audio_format"
      case tools
      case toolChoice = "tool_choice"
      case temperature
      case maxResponseOutputTokens = "max_response_output_tokens"
      case conversation
      case metadata
      case input
   }
}

public enum ConversationType: String, Codable {
   case auto
   case none
}
